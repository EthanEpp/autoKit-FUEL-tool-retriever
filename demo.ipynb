{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1496c44-b2c6-4bae-8069-cf5f9f8eb6b5",
   "metadata": {},
   "source": [
    "# AutoKit FUEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60e09d-afdc-417e-85f5-c152d080ede2",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a639652-f956-413e-a93f-ebe2d0f20c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain langchain-community langchain-text-splitters langchain-anthropic langchain-openai langgraph langgraph-sdk beautifulsoup4 chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1df75d-6148-4dcb-a79e-57a3eab5e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"ANTHROPIC_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "_set_env(\"LANGCHAIN_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8a6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "for var in [\"OPENAI_API_KEY\", \"ANTHROPIC_API_KEY\", \"TAVILY_API_KEY\", \"LANGCHAIN_API_KEY\"]:\n",
    "        val = os.environ.get(var)\n",
    "        if val:\n",
    "            print(f\"{var} is set (length={len(val)} chars)\")\n",
    "        else:\n",
    "            print(f\"{var} is NOT set\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae481e2-8295-4ad5-b6cd-8efcf4f349ae",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b6386-7aa8-4424-a34d-b730beba42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Annotated, Iterator, Literal, TypedDict\n",
    "import re\n",
    "import json\n",
    "from typing import Annotated, Iterator, TypedDict, Literal\n",
    "\n",
    "import requests\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import web_base\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# ------------------ NEW IMPORTS FOR YOU.COM ------------------\n",
    "from langchain_community.tools.you import YouSearchTool\n",
    "from langchain_community.utilities.you import YouSearchAPIWrapper\n",
    "# --------------------------------------------------------------\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import BaseMessage, AIMessage, HumanMessage, convert_to_messages\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.graph import END, StateGraph, add_messages\n",
    "# from langgraph.checkpoint import MemorySaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff1b0c3-bd2a-4d14-8142-13cf566af689",
   "metadata": {},
   "source": [
    "## Set up model, retriever & tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015917e2-4f9a-4f0f-8ddd-c824e1e20859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tool_urls_from_json(path: str) -> list[str]:\n",
    "    \"\"\"\n",
    "    Read a JSON array of tool definitions from `path` and return the list of 'documentation' URLs.\n",
    "    Each JSON object is expected to have a \"documentation\" field containing the URL string.\n",
    "    \"\"\"\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        tools_list = json.load(f)\n",
    "    # tools_list is expected to be a list of dicts; extract \"documentation\" from each\n",
    "    urls = []\n",
    "    for entry in tools_list:\n",
    "        doc_url = entry.get(\"documentation\")\n",
    "        if isinstance(doc_url, str) and doc_url.strip():\n",
    "            urls.append(doc_url.strip())\n",
    "            print(doc_url)\n",
    "    return urls\n",
    "\n",
    "# Point to your local improved_tools.json\n",
    "TOOL_JSON_PATH = \"./improved_tools.json\"\n",
    "TOOL_DOC_URLS = load_tool_urls_from_json(TOOL_JSON_PATH)\n",
    "\n",
    "\n",
    "NEWLINE_RE = re.compile(\"\\n+\")\n",
    "\n",
    "class ToolDocsLoader:\n",
    "    def __init__(self, url: str):\n",
    "        self.url = url\n",
    "\n",
    "    def load(self) -> list[Document]:\n",
    "        # (Example: scrape tool name, description, usage code, etc.)\n",
    "        import requests\n",
    "        from bs4 import BeautifulSoup\n",
    "\n",
    "        resp = requests.get(self.url)\n",
    "        soup = BeautifulSoup(resp.text, \"html.parser\")\n",
    "\n",
    "        # Example heuristic—adjust based on actual page structure:\n",
    "        tool_name = soup.find(\"h1\").get_text().strip()\n",
    "        description_paragraphs = soup.find_all(\"p\", limit=2)\n",
    "        usage_blocks = soup.find_all(\"pre\")\n",
    "        \n",
    "        pieces = [f\"Tool: {tool_name}\"]\n",
    "        for p in description_paragraphs:\n",
    "            pieces.append(\"Description: \" + p.get_text().strip())\n",
    "        for code_block in usage_blocks:\n",
    "            pieces.append(\"Example:\\n\" + code_block.get_text())\n",
    "        page_text = \"\\n\\n\".join(pieces) + f\"\\n\\nSource: {self.url}\"\n",
    "        return [Document(page_content=page_text, metadata={\"source\": self.url})]\n",
    "\n",
    "\n",
    "def prepare_tool_documents(urls: list[str]) -> list[Document]:\n",
    "    # Choose whether to split or not. If each tool doc is already small, skip splitting.\n",
    "    all_docs: list[Document] = []\n",
    "    for url in urls:\n",
    "        print(url)\n",
    "        loader = ToolDocsLoader(url)\n",
    "        page_docs = loader.load()\n",
    "        all_docs.extend(page_docs)\n",
    "    \n",
    "    # Option A: If you want to split large pages into chunks:\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\n",
    "            r\"^Tool:\",      # whenever you see “Tool:” at the start of a line\n",
    "            r\"\\n\\n+\"        # or multiple blank lines\n",
    "        ],\n",
    "        is_separator_regex=True,\n",
    "        chunk_size=800\n",
    "    )\n",
    "    return text_splitter.split_documents(all_docs)\n",
    "\n",
    "    # Option B (if every tool doc is already short):\n",
    "    # return all_docs\n",
    "\n",
    "\n",
    "def get_tool_retriever() -> BaseRetriever:\n",
    "    print(TOOL_DOC_URLS)\n",
    "    documents = prepare_tool_documents(TOOL_DOC_URLS)\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        collection_name=\"tool-rag-chroma\",\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "    )\n",
    "    return vectorstore.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f499d2a4-a86d-463d-8739-0c0b183d2015",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\", temperature=0)\n",
    "print(\"step1\")\n",
    "# retriever = get_retriever()\n",
    "retriever = get_tool_retriever()\n",
    "print(\"step2\")\n",
    "\n",
    "tavily_search_tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "print(\"step3\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad70cfd-2737-40bd-8430-7aeece7d1e7e",
   "metadata": {},
   "source": [
    "## Set up graph state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad58523-c633-42ff-9c09-b8080a0735d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[BaseMessage], add_messages]\n",
    "    question: str\n",
    "    documents: list[Document]\n",
    "    candidate_answer: str\n",
    "    retries: int\n",
    "    web_fallback: bool\n",
    "    searched: bool\n",
    "    user_feedback: str\n",
    "    sample_code: str\n",
    "\n",
    "\n",
    "class GraphConfig(TypedDict):\n",
    "    max_retries: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85f5634-c6e1-489d-947c-dfc95d79e43f",
   "metadata": {},
   "source": [
    "## Set up graph nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a8987-e086-49c1-a391-8cb9f26dfb33",
   "metadata": {},
   "source": [
    "### Document search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3667fe23-cf91-45b3-a628-4541b55c3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RETRIES = 3\n",
    "VERBOSE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add984f9-2ecd-4018-8de8-4f06c582c2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_search(state: GraphState):\n",
    "    \"\"\"\n",
    "    Retrieve documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---RETRIEVE---\")\n",
    "\n",
    "    question = convert_to_messages(state[\"messages\"])[-1].content\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    # retrieved = len(documents) > 0\n",
    "\n",
    "\n",
    "    return {\"documents\": documents, \"question\": question, \"web_fallback\": True, \"searched\": False}\n",
    "    # return {\"documents\": documents, \"question\": question, \"web_fallback\": True, \"retrieved\": retrieved}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b6c18e-a946-48c9-be2c-237ba57d7cea",
   "metadata": {},
   "source": [
    "### Generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4f6f09-91c6-4cf2-810d-9e55e63006c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG_PROMPT: ChatPromptTemplate = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "TOOL_RAG_SYSTEM = \"\"\"\n",
    "You are “ToolFinderGPT,” an assistant that helps users pick the best LangChain/third-party tool for their use-case.  \n",
    "You will be given:\n",
    "\n",
    "1. A list of “Documents” (each one is a tool description, including the tool’s name, a one-sentence summary, a usage example, and the source URL).  \n",
    "2. A user’s query (e.g. “I need a tool to fetch Wikipedia articles.” “I want a tool to summarize a URL.”).\n",
    "\n",
    "Your job:\n",
    "- Choose exactly one tool from the Documents that best matches the user’s use-case.\n",
    "- Output:\n",
    "\n",
    "    Recommended Tool: <ToolName>\n",
    "    Description: <one-sentence description from the Document>\n",
    "    \n",
    "    ```python\n",
    "    <import‐and‐call stub>\n",
    "    ```\n",
    "\n",
    "If the retrieved Documents do not contain any suitable tool, say “I’m sorry, I couldn’t find a tool that meets your requirements.” \n",
    "\"\"\"\n",
    "\n",
    "TOOL_RAG_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", TOOL_RAG_SYSTEM),\n",
    "    (\"user\", \"Context (tool descriptions):\\n\\n{context}\\n\\nUser’s query: {question}\\n\\nProvide your answer:\")\n",
    "])\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---GENERATE---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    retries = state[\"retries\"] if state.get(\"retries\") is not None else -1\n",
    "\n",
    "    # rag_chain = RAG_PROMPT | llm | StrOutputParser()\n",
    "    # generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    tool_rag_chain = TOOL_RAG_PROMPT | llm | StrOutputParser()\n",
    "    generation = tool_rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"retries\": retries + 1, \"candidate_answer\": generation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437e1dcf-bb0a-4fbe-914a-0b662f631dfb",
   "metadata": {},
   "source": [
    "### Rewrite question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b2b61b-f3ce-41e7-81d6-9c75c649289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_REWRITER_SYSTEM = \"\"\"\n",
    "You a question re-writer that converts an input question to a better version that is optimized for vectorstore tool retrieval.\n",
    "Look at the input and try to reason about the underlying semantic intent / meaning—specifically, transform natural language “I need X” into a concise “tool for X” query.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "QUERY_REWRITER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", QUERY_REWRITER_SYSTEM),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Here is the initial question: \\n\\n {question} \\n Formulate an improved question.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def transform_query(state: GraphState):\n",
    "    \"\"\"\n",
    "    Transform the query to produce a better question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Updates question key with a re-phrased question\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---TRANSFORM QUERY---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Re-write question\n",
    "    query_rewriter = QUERY_REWRITER_PROMPT | llm | StrOutputParser()\n",
    "    better_question = query_rewriter.invoke({\"question\": question})\n",
    "    return {\"question\": better_question}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675ecd66",
   "metadata": {},
   "source": [
    "# React Web Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8480ddc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tavily_search_fn(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Calls the TavilySearchResults tool under the hood.\n",
    "    Returns a plain text blob (all hit contents joined with separators).\n",
    "    \"\"\"\n",
    "    # invoke() expects a string query and returns a list of dicts with \"content\"\n",
    "    results = tavily_search_tool.invoke(query)\n",
    "    if not results:\n",
    "        return \"No results found.\"\n",
    "    # Join all the result[\"content\"] fields into one long text string\n",
    "    return \"\\n\\n\".join([hit[\"content\"] for hit in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a563ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "# 2.1) A brief system‐prompt that tells Claude to act as a “tool‐finder” agent.\n",
    "REACT_PROMPT = \"\"\"\n",
    "You are “ToolFinderAgent,” a ReAct agent whose sole job is to search for and locate an LLM‐agent‐tool (or general API) that fulfills the user’s request/goal.\n",
    "You do ​not​ need to already know the tool’s name—you will search for it.  \n",
    "Your search strategy must be:\n",
    "\n",
    "1. First attempt to find a suitable tool by querying LangChain or LangGraph documentation.  \n",
    "   • For example, if the user wants a “calculator,” your first query might be “langchain calculator tool” or “langgraph calculator tool”  \n",
    "   • To do that, call the tool `tavily_search_fn` with that LangChain/LangGraph‐specific query.\n",
    "\n",
    "2. If the LangChain/LangGraph query yields no relevant results, broaden your search to “any tool or API” that can accomplish the goal.  \n",
    "   • For instance, if you can’t find a LangChain calculator, you might search “LLM Calculator Tool Api” or “online calculator API.”  \n",
    "   • Again, use `tavily_search_fn` for this broader query.\n",
    "\n",
    "3. If the tool API query yields no relevant results, think critically and creatively about if there are any other tools that we can use to accomplish this goal, that aren't exactly what they initially asked for, but can be utilized to accomplish the goal.  \n",
    "   • For instance, if you can’t find a tool calculator API, you reason that you can also do calculator based calculations in a python script so you might search “Python Environmet Tool API”.\n",
    "   • Again, use `tavily_search_fn` for this broader query.\n",
    "\n",
    "4. Each time you use `tavily_search_fn`, show your “Thought:” with the exact query you intend to run, then run `Action: tavily_search_fn` with that query.  \n",
    "   • After you see `Observation: ...` (the returned text), think again (“Is this result relevant?”).  \n",
    "   • If relevant, you may stop searching. If not, think of a refined or broader query and call `tavily_search_fn` again.\n",
    "\n",
    "5. Once you have identified a successful documentation link or tool name, output exactly one final “Answer:” message in plain text (no code fences).  \n",
    "   • That “Answer:” should specify which tool or API you found, and include its documentation URL.  \n",
    "   • Do not output any JSON—just human‐readable text like:  \n",
    "     “Answer: I found the ‘LangChain Python Calculator Tool’ at https://python.langchain.com/docs/integrations/tools/calculator/ which fulfills your request.”  \n",
    "\n",
    "Remember:  \n",
    "- You may call `tavily_search_fn(...)` multiple times if necessary  \n",
    "- Always start with a LangChain/LangGraph‐specific query before widening to general APIs  \n",
    "- Show Thought/Action/Observation for each step so the chain of reasoning is transparent.  \n",
    "- Always return the link to the documentation of the tool if you find one.\n",
    "\"\"\"\n",
    "\n",
    "react_agent = create_react_agent(\n",
    "    model=\"anthropic:claude-3-5-sonnet-20240620\",\n",
    "    tools=[tavily_search_fn],\n",
    "    prompt=REACT_PROMPT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de5a321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(state: GraphState) -> dict:\n",
    "    \"\"\"\n",
    "    Run a ReAct agent that uses tavily_search_fn to find (or reason about) a tool.\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---RUNNING ReAct‐BASED TOOL SEARCH---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    if VERBOSE:\n",
    "        print(\"QUESTION:\", question)\n",
    "    messages = [\n",
    "        HumanMessage(content=question)\n",
    "    ]\n",
    "    \n",
    "    # 1) Invoke the ReAct agent by passing {\"question\": question}.\n",
    "    #    The agent’s internal prompt is REACT_PROMPT, which expects {question}.\n",
    "    try:\n",
    "        result = react_agent.invoke({\"messages\": messages})\n",
    "    except Exception as e:\n",
    "        # If the agent fails for any reason, bail out with an empty Document\n",
    "        if VERBOSE:\n",
    "            print(\"ReAct agent failed:\", e)\n",
    "        return {\n",
    "            \"documents\": state.get(\"documents\", []),\n",
    "            \"web_fallback\": False,\n",
    "            \"searched\": False\n",
    "        }\n",
    "\n",
    "    # 2) The agent returns either a dict with \"content\" or directly a string\n",
    "    if isinstance(result, dict) and \"content\" in result:\n",
    "        agent_response = result[\"content\"].strip()\n",
    "    else:\n",
    "        agent_response = str(result).strip()\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(\"AGENT RESPONSE:\", agent_response)\n",
    "\n",
    "    # 3) Wrap that response in a Document\n",
    "    new_doc = Document(page_content=agent_response, metadata={\"source\": \"react_tool_search\"})\n",
    "    documents = state.get(\"documents\", []) + [new_doc]\n",
    "\n",
    "    # 4) Indicate that we did perform a “search”\n",
    "    return {\n",
    "        \"documents\": documents,\n",
    "        \"web_fallback\": False,\n",
    "        \"searched\": True\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f002730-1703-4448-a2f3-f9ab1812003e",
   "metadata": {},
   "source": [
    "### Web search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a710697",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_QUERY_SYSTEM = \"\"\"\n",
    "You are a search‐query optimizer specifically for Tavily Search.  \n",
    "When given a user’s question (and optional context), your job is to produce a concise, Tavily‐friendly search query\n",
    "that will maximize relevant results.  You will only be searching for LLM Agent Tool api and documentation. Do NOT return any explanation—just output the single line of text\n",
    "that should be sent to Tavily.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "SEARCH_QUERY_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", SEARCH_QUERY_SYSTEM),\n",
    "    (\"user\", \"User question: {question}\\n\\n---\\nGenerate a Tavily search query:\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c338af59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def format_search_query(state: GraphState) -> dict:\n",
    "    \"\"\"\n",
    "    Take state[\"question\"] and ask Claude to rewrite it into a concise Tavily‐optimized query.\n",
    "    Returns: { \"search_query\": <rewritten string> }.\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---FORMATTING SEARCH QUERY (no context)---\")\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    # Now our prompt only needs `{\"question\": ...}` because we removed {context} above.\n",
    "    search_query_chain = SEARCH_QUERY_PROMPT | llm | StrOutputParser()\n",
    "    better_query = search_query_chain.invoke({\"question\": question})\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(f\"→ Formatted search query: {better_query!r}\")\n",
    "    return {\"search_query\": better_query}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615c3df-7be5-4de5-9a74-e5f8565abff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trad_web_search(state: GraphState) -> dict:\n",
    "    \"\"\"\n",
    "    Perform a Tavily search using an LLM‐rewritten query (no context from state[\"documents\"]).\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---RUNNING WEB SEARCH (with optimized query)---\")\n",
    "\n",
    "    # 3.1) Rewrite just the question\n",
    "    formatted = format_search_query(state)\n",
    "    if formatted != None:\n",
    "        searched = True\n",
    "    else:\n",
    "        searched = False\n",
    "\n",
    "    search_query = formatted[\"search_query\"]\n",
    "    print(\"SEARCH QUERY:\", search_query)\n",
    "    # 3.2) Call Tavily with the rewritten query\n",
    "    search_results = tavily_search_tool.invoke(search_query)\n",
    "\n",
    "    # 3.3) Package Tavily’s hits into a single Document\n",
    "    search_content = \"\\n\\n\".join([r[\"content\"] for r in search_results])\n",
    "    new_doc = Document(page_content=search_content, metadata={\"source\": \"tavily\"})\n",
    "\n",
    "    # 3.4) Append to state[\"documents\"] and disable further web‐fallback\n",
    "    documents = state.get(\"documents\", [])\n",
    "    documents.append(new_doc)\n",
    "    \n",
    "    return {\"documents\": documents, \"web_fallback\": False, \"searched\": searched}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d65a37-3860-4bae-882b-8e12604aad8a",
   "metadata": {},
   "source": [
    "### Finalize response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce04288-19fa-406c-8911-4ea8cf770927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_response(state: GraphState):\n",
    "    if VERBOSE:\n",
    "        print(\"---FINALIZING THE RESPONSE---\")\n",
    "\n",
    "    return {\"messages\": [AIMessage(content=state[\"candidate_answer\"])]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f079c3",
   "metadata": {},
   "source": [
    "### Add Tool to Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62afb81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "TOOL_ADDER_SYSTEM = \"\"\"\n",
    "You are a tool adder system that takes an input containing a structured description of a tool, and generates a stub in a specific format that will be added to a json of tools.\n",
    "\"\"\"\n",
    "\n",
    "TASK = \"\"\"Here is the tool description: \\n\\n {description} \\n Create a single stub for this tool based on this description. Format your response exactly the same as the following examples. Here are three examples of tool stubs:\\n\\n\n",
    "{{\n",
    "  \"name\": \"OpenAPI Toolkit\",\n",
    "  \"description\": \"Call any REST API via OpenAPI specs\",\n",
    "  \"programming_language\": \"python\",\n",
    "  \"module\": \"langchain_experimental.toolkits.open_api\",\n",
    "  \"class\": \"OpenAPIToolkit\",\n",
    "  \"init_args\": {{ \"spec_paths\": \"./manifests\" }},\n",
    "  \"openapi\": \"./manifests\",\n",
    "  \"pricing\": \"Free (tooling only)\",\n",
    "  \"documentation\": \"https://python.langchain.com/docs/integrations/tools/openapi/\"\n",
    "}},\n",
    "{{\n",
    "  \"name\": \"NLA Toolkit\",\n",
    "  \"description\": \"Natural-language API invocation\",\n",
    "  \"programming_language\": \"python\",\n",
    "  \"module\": \"langchain_experimental.toolkits.nla\",\n",
    "  \"class\": \"NLAToolkit\",\n",
    "  \"init_args\": {{ \"nla_url\": \"${{NLA_SERVER_URL}}\" }},\n",
    "  \"openapi\": null,\n",
    "  \"pricing\": \"Free\",\n",
    "  \"documentation\": \"https://python.langchain.com/docs/integrations/tools/openapi_nla/\"\n",
    "}},\n",
    "{{\n",
    "  \"name\": \"Zapier NLA\",\n",
    "  \"description\": \"Zapier Natural Language Actions integration\",\n",
    "  \"programming_language\": \"python\",\n",
    "  \"module\": \"langchain.tools.zapier\",\n",
    "  \"class\": \"ZapierNLATool\",\n",
    "  \"init_args\": {{ \"api_key\": \"${{ZAPIER_NLA_KEY}}\" }},\n",
    "  \"openapi\": null,\n",
    "  \"pricing\": \"Paid (Zapier plan)\",\n",
    "  \"documentation\": \"https://python.langchain.com/docs/integrations/tools/zapier/\"\n",
    "}},\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "TOOL_ADDER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", TOOL_ADDER_SYSTEM),\n",
    "        (\n",
    "            \"human\",\n",
    "            TASK,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "def add_tool_to_database(state: GraphState):\n",
    "    \"\"\"\n",
    "    Adds a new tool to the local database of tools if the pipeline used an external search.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        Nothing, but adds a new entry to the local database of tools\n",
    "    \"\"\"\n",
    "\n",
    "    if not state.get(\"searched\", False):\n",
    "        print(\"STATE SEARCHED\")\n",
    "        return state\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(\"---ADDING TOOL TO DATABASE---\")\n",
    "\n",
    "    # Generate the tool stub\n",
    "    tool_adder = TOOL_ADDER_PROMPT | llm | StrOutputParser()\n",
    "\n",
    "    tool_stub = tool_adder.invoke({\"description\": state[\"candidate_answer\"]})\n",
    "\n",
    "    # Parse the tool stub for the essential information\n",
    "    # Since you're using StrOutputParser(), tool_stub is already a string\n",
    "    text = tool_stub.strip()\n",
    "    \n",
    "    # if VERBOSE:\n",
    "    #     print(f\"Generated tool stub: {text}\")\n",
    "    \n",
    "    # Try to parse the JSON directly first\n",
    "    try:\n",
    "        tool_stub_dict = json.loads(text)\n",
    "    except json.JSONDecodeError:\n",
    "        # If direct parsing fails, try to extract JSON block using regex\n",
    "        # Find the outermost JSON object - start from first { and find matching }\n",
    "        start = text.find('{')\n",
    "        if start == -1:\n",
    "            print(\"No opening brace found in response.\")\n",
    "            print(f\"Raw response: {text}\")\n",
    "            return state\n",
    "            \n",
    "        # Count braces to find the matching closing brace\n",
    "        brace_count = 0\n",
    "        end = start\n",
    "        for i, char in enumerate(text[start:], start):\n",
    "            if char == '{':\n",
    "                brace_count += 1\n",
    "            elif char == '}':\n",
    "                brace_count -= 1\n",
    "                if brace_count == 0:\n",
    "                    end = i\n",
    "                    break\n",
    "        \n",
    "        if brace_count != 0:\n",
    "            print(\"No matching closing brace found.\")\n",
    "            print(f\"Raw response: {text}\")\n",
    "            return state\n",
    "            \n",
    "        json_text = text[start:end+1]\n",
    "        \n",
    "        # if VERBOSE:\n",
    "        #     print(f\"Extracted JSON: {json_text}\")\n",
    "            \n",
    "        try:\n",
    "            tool_stub_dict = json.loads(json_text)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Failed to parse JSON: {e}\")\n",
    "            print(f\"Extracted JSON: {json_text}\")\n",
    "            print(f\"Raw response: {text}\")\n",
    "            return state\n",
    "    \n",
    "    # add the tool to the database\n",
    "    # Load the existing file\n",
    "    try:\n",
    "        with open(\"improved_tools.json\", \"r\") as f:\n",
    "            tool_list = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        tool_list = []  # Create empty list if file doesn't exist\n",
    "\n",
    "    # Check if a tool with the same name already exists\n",
    "    new_tool_name = tool_stub_dict.get(\"name\", \"\")\n",
    "    existing_names = [tool.get(\"name\", \"\") for tool in tool_list]\n",
    "    \n",
    "    if new_tool_name in existing_names:\n",
    "        if VERBOSE:\n",
    "            print(f\"Tool '{new_tool_name}' already exists in database. Skipping addition.\")\n",
    "        return state\n",
    "    \n",
    "    # Append the new stub\n",
    "    tool_list.append(tool_stub_dict)\n",
    "\n",
    "    # Write back the file\n",
    "    with open(\"improved_tools.json\", \"w\") as f:\n",
    "        json.dump(tool_list, f, indent=4)\n",
    "    \n",
    "    if VERBOSE:\n",
    "        print(f\"Successfully added tool '{new_tool_name}' to database.\")\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d606ff4c",
   "metadata": {},
   "source": [
    "# Add verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9e6c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, Dict, Any\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import json\n",
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "def extract_main_text(html: str) -> str:\n",
    "    \"\"\"\n",
    "    Given the raw HTML string `html`, return only the \"main content\" text.\n",
    "    1) If there is a <main> tag, return its text (stripped of excess whitespace).\n",
    "    2) Otherwise, get all text, but remove everything between\n",
    "       'Skip to main content' and 'On this page' (inclusive).\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # 1) If there's a <main> element, use that:\n",
    "    main_tag = soup.find(\"main\")\n",
    "    if main_tag:\n",
    "        return \"\\n\".join(line.strip() for line in main_tag.get_text().splitlines() if line.strip())\n",
    "\n",
    "    # 2) Otherwise, fall back to full-text minus the \"Skip to main content\" → \"On this page\" block:\n",
    "    all_text = soup.get_text(separator=\"\\n\")\n",
    "\n",
    "    start_marker = \"Skip to main content\"\n",
    "    end_marker   = \"On this page\"\n",
    "\n",
    "    start_idx = all_text.find(start_marker)\n",
    "    end_idx   = all_text.find(end_marker)\n",
    "\n",
    "    if start_idx != -1 and end_idx != -1 and end_idx > start_idx:\n",
    "        # Remove the entire chunk from start_marker up to end_marker\n",
    "        cleaned = all_text[:start_idx] + all_text[end_idx + len(end_marker):]\n",
    "    else:\n",
    "        cleaned = all_text\n",
    "\n",
    "    # Clean up duplicate blank lines or leading/trailing whitespace\n",
    "    lines = [line.strip() for line in cleaned.splitlines() if line.strip()]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "            \n",
    "class ToolStub(BaseModel):\n",
    "    name: str\n",
    "    description: str\n",
    "    programming_language: str\n",
    "    module: str\n",
    "    class_: str = Field(alias=\"class\")  # `class` is a Python keyword, so alias it\n",
    "    init_args: Dict[str, Any]\n",
    "    openapi: Optional[str]            # JSON `null` → Python None\n",
    "    pricing: Optional[str]  \n",
    "    documentation: Optional[str] \n",
    "\n",
    "class VerifiedToolStub(ToolStub):\n",
    "    verified: bool\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "import json\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 1) ReAct prompt for the “fixer” agent\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "FIXER_REACT_PROMPT = \"\"\"\n",
    "You are “ToolFixerAgent,” a ReAct agent whose job is to take an outdated tool stub (provided below as the entire user message) \n",
    "and find the correct, up‐to‐date documentation URL (and any changed fields) for that tool.  \n",
    "You do not assume the original “documentation” URL still works.\n",
    "\n",
    "Whenever you receive the user’s message (which is the entire outdated tool JSON), follow these steps EXACTLY:\n",
    "\n",
    "1. Thought: Read the JSON stub (fields: name, description, programming_language, module, class, init_args, openapi, pricing, documentation).\n",
    "   Extract the “name” field and formulate a concise LangChain/LangGraph–specific search query, e.g. “langchain <name> documentation” \n",
    "   or “langgraph <name> docs.”\n",
    "\n",
    "2. Action: Call tavily_search_fn with that query.  \n",
    "   You must write exactly:\n",
    "     Action: tavily_search_fn\n",
    "     Input: \"<your query here>\"\n",
    "\n",
    "3. Observation: You will get back some text from Tavily. Inspect it.  \n",
    "   • If you find a valid documentation URL or updated import hints, stop.  \n",
    "   • Otherwise, Thought: “No LangChain page found—broaden to any Python <name> API”  \n",
    "     then Action: tavily_search_fn with “Python <name> API” (or similar).\n",
    "\n",
    "4. Repeat Thought/Action/Observation until you identify a working documentation URL \n",
    "   (and any changed class/module imports).\n",
    "\n",
    "5. Finally, output exactly one line starting with “Answer: ” followed by a single JSON object \n",
    "   that matches the `ToolStub` schema (all fields—name, description, programming_language, module, \n",
    "   class, init_args, openapi, pricing, documentation—must appear).  \n",
    "   • If you absolutely cannot find a valid documentation URL, set `\"documentation\": null` \n",
    "     and leave other fields as originally or defaulted.\n",
    "\n",
    "Do NOT output any text outside of “Thought: …”, “Action: …”, “Observation: …”, \n",
    "and the final “Answer: { … }” line.  \n",
    "\"\"\"\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Create the ReAct‐style fixer agent (one tool: tavily_search_fn)\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "react_fixer_agent = create_react_agent(\n",
    "    model=\"anthropic:claude-3-5-sonnet-20240620\",\n",
    "    tools=[tavily_search_fn],\n",
    "    prompt=FIXER_REACT_PROMPT\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "VERIFIER_SYSTEM = \"\"\"\n",
    "You are a LLM agent tool‐verifier assistant.  A JSON object describing a third‐party agent tool (name, description, module, pricing, documentation URL, etc.) is provided, along with the text of its official documentation page. These tools are used for extending LLM agent capabilities via an api.  Your job is to:\n",
    "\n",
    "1. Check each field in the JSON (name, description, programming_language, module, class, init_args, openapi, pricing, documentation) against the documentation page.\n",
    "2. If any field is incorrect or out‐of‐date (e.g. pricing has changed, the description could be richer, the “class” or import path has moved, etc.), fix it. You should also add to or expand on the description to make it clearer about what the tool does.\n",
    "3. If you believe a field is already correct and up‐to‐date, it is okay to leave it as‐is.\n",
    "4. Return exactly one JSON object (no extra commentary, no markdown fences) that contains the “fully verified” or “updated” stub.  \n",
    "\n",
    "You may assume the documentation page text is accurate and up‐to‐date.  If you cannot find evidence for a particular field (for example, pricing isn’t mentioned), leave the original value as‐is, but set a new key `\"verified\": false` to signal uncertainty.  Otherwise, set `\"verified\": true`.  If you\n",
    "\"\"\"\n",
    "\n",
    "VERIFIER_PROMPT = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", VERIFIER_SYSTEM),\n",
    "    (\n",
    "        \"user\",\n",
    "        \"Here is the original tool JSON:\\n\\n{tool_json}\\n\\n\"\n",
    "        \"Here is the TEXT of its documentation page (HTML stripped to plaintext):\\n\\n{page_text}\\n\\n\"\n",
    "        \"---\\n\"\n",
    "        \"Produce the updated JSON stub now:\"\n",
    "    ),\n",
    "])\n",
    "# 1) Build a chain that outputs VerifiedToolStub\n",
    "verifier_chain = (VERIFIER_PROMPT \n",
    "                  | llm.with_structured_output(VerifiedToolStub))\n",
    "\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import json\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Dict, List\n",
    "\n",
    "# (Assume extract_main_text, VerifiedToolStub, verifier_chain, _add_to_missing_and_fix_and_fix, VERBOSE, etc. are defined above.)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def verify_tool_entry(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Verifies (and potentially updates) each tool stub in improved_tools.json by fetching its\n",
    "    documentation URL. If fetching or parsing fails, the original stub is moved to missing_tools.json.\n",
    "    Otherwise, a VerifiedToolStub is created and written to improved_tools.json.\n",
    "    \"\"\"\n",
    "    stubtemp = False\n",
    "    \n",
    "    # if (state.get(\"searched\") != False) && stubtemp:\n",
    "    if stubtemp: #dont burn credits\n",
    "        if VERBOSE:\n",
    "            print(\"---VERIFYING TOOL ENTRIES---\")\n",
    "\n",
    "        # 1) Load improved_tools.json (all stubs to verify)\n",
    "        try:\n",
    "            with open(\"improved_tools.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            # with open(\"broken_tools.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                tool_list: List[Dict] = json.load(f)\n",
    "        except (FileNotFoundError, json.JSONDecodeError):\n",
    "            if VERBOSE:\n",
    "                print(\"improved_tools.json not found or invalid → skipping verification.\")\n",
    "                # print(\"broken_tools.json not found or invalid → skipping verification.\")\n",
    "            return state\n",
    "\n",
    "        if not tool_list:\n",
    "            if VERBOSE:\n",
    "                print(\"improved_tools.json is empty → skipping.\")\n",
    "                # print(\"broken_tools.json is empty → skipping.\")\n",
    "            return state\n",
    "\n",
    "        # 2) Iterate over each stub\n",
    "        for original_stub in tool_list:\n",
    "            name = original_stub.get(\"name\", \"<unknown>\")\n",
    "            doc_url = original_stub.get(\"documentation\")\n",
    "            if VERBOSE:\n",
    "                print(f\"\\n---VERIFYING TOOL: {name}---\")\n",
    "                print(\"DOC_URL:\", doc_url)\n",
    "\n",
    "            # If there's no documentation URL, move to missing\n",
    "            if not doc_url:\n",
    "                if VERBOSE:\n",
    "                    print(f\"No documentation URL for '{name}' → marking as missing.\")\n",
    "                _add_to_missing_and_fix(original_stub)\n",
    "                continue  # proceed to next stub\n",
    "\n",
    "            # 3) Try to fetch and extract main content\n",
    "            try:\n",
    "                resp = requests.get(doc_url, timeout=10)\n",
    "                resp.raise_for_status()\n",
    "                html = resp.text\n",
    "                page_text = extract_main_text(html)\n",
    "\n",
    "                # If extract_main_text returned empty or whitespace only, treat as failure\n",
    "                if not page_text.strip():\n",
    "                    if VERBOSE:\n",
    "                        print(f\"Fetched page for '{name}', but extracted text is empty → marking as missing.\")\n",
    "                    _add_to_missing_and_fix(original_stub)\n",
    "                    continue\n",
    "\n",
    "            except Exception as e:\n",
    "                if VERBOSE:\n",
    "                    print(f\"Error fetching or parsing page at {doc_url}: {e}\")\n",
    "                _add_to_missing_and_fix(original_stub)\n",
    "                continue\n",
    "\n",
    "            # 4) Prepare inputs for the verifier chain\n",
    "            stub_json_str = json.dumps(original_stub, indent=2)\n",
    "            verifier_input = {\n",
    "                \"tool_json\": stub_json_str,\n",
    "                \"page_text\": page_text[:8000]  # truncate if very long\n",
    "            }\n",
    "\n",
    "            # 5) Invoke structured verifier (might raise if validation fails)\n",
    "            try:\n",
    "                verified_stub: VerifiedToolStub = verifier_chain.invoke(verifier_input)\n",
    "            except Exception as e:\n",
    "                if VERBOSE:\n",
    "                    print(f\"Verification LLM failed for '{name}': {e}\")\n",
    "                _add_to_missing_and_fix(original_stub)\n",
    "                continue\n",
    "\n",
    "            # 6) Load (or create) improved_tools.json, with JSONDecodeError handling\n",
    "            try:\n",
    "                with open(\"improved_tools.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "                    improved_list: List[Dict] = json.load(f)\n",
    "            except (FileNotFoundError, json.JSONDecodeError):\n",
    "                improved_list = []\n",
    "\n",
    "            # 7) Convert Pydantic → dict (including “verified” field)\n",
    "            # new_dict = verified_stub.dict(by_alias=True)\n",
    "            new_dict = verified_stub.model_dump(by_alias=True)\n",
    "\n",
    "            # 8) Replace or append in improved_tools.json\n",
    "            existing_names = [t.get(\"name\") for t in improved_list]\n",
    "            if verified_stub.name in existing_names:\n",
    "                idx = existing_names.index(verified_stub.name)\n",
    "                improved_list[idx] = new_dict\n",
    "                if VERBOSE:\n",
    "                    print(f\"Replaced entry for '{verified_stub.name}' in improved_tools.json.\")\n",
    "            else:\n",
    "                improved_list.append(new_dict)\n",
    "                if VERBOSE:\n",
    "                    print(f\"Appended '{verified_stub.name}' to improved_tools.json.\")\n",
    "\n",
    "            # 9) Write back improved_tools.json\n",
    "            with open(\"improved_tools.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(improved_list, f, indent=4)\n",
    "\n",
    "            if VERBOSE:\n",
    "                print(f\"Successfully wrote verified stub for '{verified_stub.name}'.\")\n",
    "\n",
    "    return state\n",
    "\n",
    "import json\n",
    "from typing import Dict, List\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "def _add_to_missing_and_fix(tool_stub: Dict) -> None:\n",
    "    \"\"\"\n",
    "    1) Append tool_stub to missing_tools.json if not already present.\n",
    "    2) Invoke react_fixer_agent; normalize its return so that whether AIMessage.content is a string or list,\n",
    "       we end up with a single text blob. Extract the JSON after \"Answer:\", validate via ToolStub, and \n",
    "       write to fixed_tools.json.\n",
    "    \"\"\"\n",
    "    name = tool_stub.get(\"name\", \"<unknown>\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────────────────────\n",
    "    # Part A: Append to missing_tools.json\n",
    "    # ──────────────────────────────────────────────────────────────────────────\n",
    "    try:\n",
    "        with open(\"missing_tools.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            missing_list: List[Dict] = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        missing_list = []\n",
    "\n",
    "    existing_names = [t.get(\"name\") for t in missing_list]\n",
    "    if name not in existing_names:\n",
    "        missing_list.append(tool_stub)\n",
    "        with open(\"missing_tools.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(missing_list, f, indent=4)\n",
    "        if VERBOSE:\n",
    "            print(f\"Added '{name}' to missing_tools.json.\")\n",
    "    else:\n",
    "        if VERBOSE:\n",
    "            print(f\"'{name}' already in missing_tools.json; skipping append.\")\n",
    "\n",
    "    # ──────────────────────────────────────────────────────────────────────────\n",
    "    # Part B: Run the React fixer agent\n",
    "    # ──────────────────────────────────────────────────────────────────────────\n",
    "    if VERBOSE:\n",
    "        print(f\"Launching react_fixer_agent for '{name}'...\")\n",
    "\n",
    "    # 1) Build a single HumanMessage with old stub JSON\n",
    "    old_json_str = json.dumps(tool_stub, indent=2)\n",
    "    messages_in = [HumanMessage(content=old_json_str)]\n",
    "\n",
    "    # 2) Invoke the agent\n",
    "    try:\n",
    "        result = react_fixer_agent.invoke({\"messages\": messages_in})\n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"react_fixer_agent failed for '{name}': {e}\")\n",
    "        return\n",
    "\n",
    "    # 3) Normalize into a list of messages\n",
    "    if isinstance(result, dict) and \"messages\" in result:\n",
    "        messages_out = result[\"messages\"]\n",
    "    elif isinstance(result, list):\n",
    "        messages_out = result\n",
    "    else:\n",
    "        if VERBOSE:\n",
    "            print(f\"Unexpected return type from fixer agent for '{name}': {type(result)}\")\n",
    "        return\n",
    "\n",
    "    # 4) Extract the first AIMessage's content, handling str vs list\n",
    "    ai_content = None\n",
    "    for msg in messages_out:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            content = msg.content\n",
    "            # If it's already a string, just strip\n",
    "            if isinstance(content, str):\n",
    "                ai_content = content.strip()\n",
    "            # If it's a list (of dicts or other), attempt to join any 'text' fields\n",
    "            elif isinstance(content, list):\n",
    "                pieces = []\n",
    "                for element in content:\n",
    "                    if isinstance(element, dict) and \"text\" in element:\n",
    "                        pieces.append(element[\"text\"])\n",
    "                    else:\n",
    "                        pieces.append(str(element))\n",
    "                ai_content = \"\\n\".join(pieces).strip()\n",
    "            else:\n",
    "                # Fallback: stringify\n",
    "                ai_content = str(content).strip()\n",
    "            break\n",
    "\n",
    "    if ai_content is None:\n",
    "        if VERBOSE:\n",
    "            print(f\"No AIMessage found in fixer output for '{name}'. Aborting fix.\")\n",
    "        return\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(\"Fixer agent normalized content:\\n\", ai_content)\n",
    "\n",
    "    # 5) Find “Answer:” and parse JSON after it\n",
    "    answer_prefix = \"Answer:\"\n",
    "    idx = ai_content.find(answer_prefix)\n",
    "    if idx == -1:\n",
    "        if VERBOSE:\n",
    "            print(f\"No 'Answer:' found in fixer output for '{name}'. Aborting fix.\")\n",
    "        return\n",
    "\n",
    "    json_part = ai_content[idx + len(answer_prefix):].strip()\n",
    "    try:\n",
    "        fixed_stub_dict = json.loads(json_part)\n",
    "    except json.JSONDecodeError as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Failed to parse JSON from fixer output for '{name}': {e}\")\n",
    "            print(\"JSON part was:\", json_part)\n",
    "        return\n",
    "\n",
    "    # 6) Validate via Pydantic ToolStub\n",
    "    try:\n",
    "        fixed_stub_obj: ToolStub = ToolStub.model_validate(fixed_stub_dict)\n",
    "    except Exception as e:\n",
    "        if VERBOSE:\n",
    "            print(f\"Pydantic validation failed for fixed stub '{name}': {e}\")\n",
    "        return\n",
    "\n",
    "    # 7) Load or create fixed_tools.json\n",
    "    try:\n",
    "        with open(\"fixed_tools.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "            fixed_list: List[Dict] = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        fixed_list = []\n",
    "\n",
    "    # 8) Replace or append\n",
    "    final_name = fixed_stub_obj.name\n",
    "    existing_names_fixed = [t.get(\"name\") for t in fixed_list]\n",
    "    if final_name in existing_names_fixed:\n",
    "        idx2 = existing_names_fixed.index(final_name)\n",
    "        fixed_list[idx2] = fixed_stub_obj.model_dump(by_alias=True)\n",
    "        if VERBOSE:\n",
    "            print(f\"Replaced '{final_name}' in fixed_tools.json.\")\n",
    "    else:\n",
    "        fixed_list.append(fixed_stub_obj.model_dump(by_alias=True))\n",
    "        if VERBOSE:\n",
    "            print(f\"Appended '{final_name}' to fixed_tools.json.\")\n",
    "\n",
    "    # 9) Write back to fixed_tools.json\n",
    "    with open(\"fixed_tools.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(fixed_list, f, indent=4)\n",
    "    if VERBOSE:\n",
    "        print(f\"Successfully wrote fixed stub for '{final_name}' to fixed_tools.json.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4221a8",
   "metadata": {},
   "source": [
    "### Human in the Loop Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f048fe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if yes - you can provide some stub code to fill in so we can generate code for them\n",
    "# if no - do another react search to find a better tool, with the user feedback\n",
    "    # put an intermediate node to collect extra user feedback\n",
    "\n",
    "def human_feedback_satisfaction(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Collect human feedback on the generated answer: checks if the tool found is satisfactory for the user.\n",
    "    Updates the state with the user's feedback (yes or no).\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---COLLECTING HUMAN FEEDBACK---\")\n",
    "    \n",
    "    user_input = input(\"Did the provided tool address your needs? (yes/no): \").strip().lower()\n",
    "\n",
    "    print(\"USER FEEDBACK:\", user_input)\n",
    "    state[\"user_feedback\"] = user_input\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016dd1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_GENERATOR_SYSTEM = \"\"\"\n",
    "You are a code generator system that takes an input containing a structured description of a tool and a specific use case, and generates code for that use case, using the provided tool.\n",
    "\"\"\"\n",
    "\n",
    "CODE_GENERATOR_TASK = \"Here is the tool description and a specific use case for this tool: \\n Description: \\n{tool_description} \\n Use case: \\n {use_case} \\n Generate code that uses the provided tool to address the specific use case.\"\n",
    "\n",
    "CODE_GENERATOR_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", CODE_GENERATOR_SYSTEM),\n",
    "        (\n",
    "            \"human\",\n",
    "            CODE_GENERATOR_TASK,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# collect more user feedback on the tool found\n",
    "# generate stub code for the tool found - use another LLM call to generate a code stub that addresses the specific use-case for the tool found\n",
    "def handle_positive_feedback(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Handle the case where the user is satisfied with the tool found.\n",
    "    In this case, we will prompt the user for the specific use-case for the tool found, and then generate a code stub that addresses the specific use-case.\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---HANDLING POSITIVE FEEDBACK---\")\n",
    "\n",
    "    user_input = input(\"Please describe your specific use-case for the tool found so we can generate some starter code for you: \").strip()\n",
    "    code_generator = CODE_GENERATOR_PROMPT | llm | StrOutputParser()\n",
    "    code_stub = code_generator.invoke({\"tool_description\": state[\"candidate_answer\"], \"use_case\": user_input})\n",
    "    state[\"sample_code\"] = code_stub\n",
    "\n",
    "    # if VERBOSE:\n",
    "    #     print(\"GENERATED CODE: \", code_stub)\n",
    "    \n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceaa200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect more user feedback on the tool found\n",
    "# run another ReAct search with the user's feedback\n",
    "def handle_negative_feedback(state: GraphState) -> GraphState:\n",
    "    \"\"\"\n",
    "    Handle the case where the user is not satisfied with the tool found.\n",
    "    This function can be extended to run another ReAct search with the user's feedback.\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---HANDLING NEGATIVE FEEDBACK---\")\n",
    "    \n",
    "    user_feedback = input(\"Please provide more details on what you were looking for: \").strip()\n",
    "    state[\"question\"] += \"Based on the user feedback and the previously retrieved tool, find a better tool than the previously retrieved one.\\n User Feedback: {user_feedback} \\n Previously Retrieved Tool: {previous_tool}\".format(user_feedback=user_feedback, previous_tool=state[\"candidate_answer\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265a4161-4d73-438a-a06d-46d5e4d8bdbb",
   "metadata": {},
   "source": [
    "## Set up edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc50bd-63d1-47d7-b99c-a49273d8aaa6",
   "metadata": {},
   "source": [
    "### Grade answer\n",
    "\n",
    "* Check hallucinations\n",
    "* Check answer relevance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da13e2d8-77cf-4401-851d-50189f8f6c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradeHallucinations(BaseModel):\n",
    "    \"\"\"Binary score for hallucination present in generation answer.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer is grounded in the facts, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "HALLUCINATION_GRADER_SYSTEM = (\n",
    "\"\"\"\n",
    "You are a grader assessing whether an LLM generation is grounded in / supported by a set of retrieved facts.\n",
    "Give a binary score 'yes' or 'no', where 'yes' means that the answer is grounded in / supported by the set of facts.\n",
    "\n",
    "IF the generation includes code examples, make sure those examples are FULLY present in the set of facts, otherwise always return score 'no'.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "HALLUCINATION_GRADER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", HALLUCINATION_GRADER_SYSTEM),\n",
    "        (\"human\", \"Set of facts: \\n\\n {documents} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class GradeAnswer(BaseModel):\n",
    "    \"\"\"Binary score to assess answer addresses question.\"\"\"\n",
    "\n",
    "    binary_score: str = Field(\n",
    "        description=\"Answer addresses the question, 'yes' or 'no'\"\n",
    "    )\n",
    "\n",
    "\n",
    "ANSWER_GRADER_SYSTEM = (\n",
    "\"\"\"\n",
    "You are a grader assessing whether an answer addresses / resolves a question.\n",
    "Give a binary score 'yes' or 'no', where 'yes' means that the answer resolves the question.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "ANSWER_GRADER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", ANSWER_GRADER_SYSTEM),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc69d62-8a06-47fa-a954-b0d3fcfad2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_generation_v_documents_and_question(state: GraphState, config) -> Literal[\"generate\", \"transform_query\", \"web_search\", \"finalize_response\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"candidate_answer\"]\n",
    "    web_fallback = state[\"web_fallback\"]\n",
    "    retries = state[\"retries\"] if state.get(\"retries\") is not None else -1\n",
    "    max_retries = config.get(\"configurable\", {}).get(\"max_retries\", MAX_RETRIES)\n",
    "\n",
    "    # this means we've already gone through web fallback and can return to the user\n",
    "    if not web_fallback:\n",
    "        return \"finalize_response\"\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(\"---CHECK HALLUCINATIONS---\")\n",
    "\n",
    "    hallucination_grader = HALLUCINATION_GRADER_PROMPT | llm.with_structured_output(GradeHallucinations)\n",
    "    hallucination_grade: GradeHallucinations = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "\n",
    "    # Check hallucination\n",
    "    if hallucination_grade.binary_score == \"no\":\n",
    "        if VERBOSE: print(\"---DECISION: GENERATION IS NOT GROUNDED IN DOCUMENTS, RE-TRY---\")\n",
    "        return \"generate\" if retries < max_retries else \"web_search\"\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(\"---DECISION: GENERATION IS GROUNDED IN DOCUMENTS---\")\n",
    "        print(\"---GRADE GENERATION vs QUESTION---\")\n",
    "\n",
    "    # Check question-answering\n",
    "    answer_grader = ANSWER_GRADER_PROMPT | llm.with_structured_output(GradeAnswer)\n",
    "    answer_grade: GradeAnswer = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "\n",
    "    if answer_grade.binary_score == \"yes\":\n",
    "        if VERBOSE: print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "        return \"finalize_response\"\n",
    "    else:\n",
    "        if VERBOSE: print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "        return \"transform_query\" if retries < max_retries else \"web_search\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad11b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_final_response(state: GraphState, config) -> Literal[\"add_tool_to_datase\", \"END\"]:\n",
    "    \"\"\"\n",
    "    Determines whether the final response the LLM gave contains a valid tool stub, or if the LLM could not find a valid tool.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    generation = state[\"candidate_answer\"]\n",
    "\n",
    "    if VERBOSE:\n",
    "        print(\"---CHECK FINAL RESPONSE---\")\n",
    "\n",
    "    # Check question-answering\n",
    "    answer_grader = ANSWER_GRADER_PROMPT | llm.with_structured_output(GradeAnswer)\n",
    "    answer_grade: GradeAnswer = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "    if answer_grade.binary_score == \"yes\":\n",
    "        if VERBOSE: print(\"---DECISION: GENERATION ADDRESSES QUESTION---\")\n",
    "        return \"finalize_response\"\n",
    "    else:\n",
    "        if VERBOSE: print(\"---DECISION: GENERATION DOES NOT ADDRESS QUESTION---\")\n",
    "        return \"END\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11277e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional edge determining which state to execute next based on user feedback\n",
    "def handle_user_feedback(state: GraphState) -> Literal[\"handle_positive_feedback\", \"handle_negative_feedback\", \"finalize_response\"]:\n",
    "    \"\"\"\n",
    "    Handle the user's feedback on the tool found.\n",
    "    If the user is satisfied, finalize the response.\n",
    "    If not, run another ReAct search with the user's feedback.\n",
    "    \"\"\"\n",
    "    if VERBOSE:\n",
    "        print(\"---HANDLING USER FEEDBACK---\")\n",
    "\n",
    "    feedback_state = state[\"user_feedback\"]\n",
    "    \n",
    "    if feedback_state == \"yes\":\n",
    "        return \"handle_positive_feedback\"\n",
    "    elif feedback_state == \"no\":\n",
    "        return \"handle_negative_feedback\"\n",
    "    else:\n",
    "        print(\"Invalid input. Please respond with 'yes' or 'no'.\")\n",
    "        return \"finalize_response\"  # No change, just return current state\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f221f884-c0b3-4b13-aedb-8106c047ae95",
   "metadata": {},
   "source": [
    "## Assemble graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf84c298-6d9f-43ff-aaaa-cece6a9c3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState, config_schema=GraphConfig)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"document_search\", document_search)\n",
    "workflow.add_node(\"generate\", generate)\n",
    "workflow.add_node(\"transform_query\", transform_query)\n",
    "workflow.add_node(\"web_search\", web_search)\n",
    "workflow.add_node(\"finalize_response\", finalize_response)\n",
    "workflow.add_node(\"add_tool_to_database\", add_tool_to_database) \n",
    "workflow.add_node(\"verify_tool_entry\", verify_tool_entry)\n",
    "\n",
    "workflow.add_node(\"human_feedback_satisfaction\", human_feedback_satisfaction)\n",
    "workflow.add_node(\"handle_positive_feedback\", handle_positive_feedback)\n",
    "workflow.add_node(\"handle_negative_feedback\", handle_negative_feedback)\n",
    "\n",
    "# Build graph\n",
    "workflow.set_entry_point(\"document_search\")\n",
    "workflow.add_edge(\"document_search\", \"generate\")\n",
    "workflow.add_edge(\"transform_query\", \"document_search\")\n",
    "workflow.add_edge(\"web_search\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question\n",
    ")\n",
    "\n",
    "# after getting the candidate answer, check with the user to see if they are satisfied with the tool found\n",
    "workflow.add_edge(\"finalize_response\", \"human_feedback_satisfaction\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"human_feedback_satisfaction\",\n",
    "    handle_user_feedback\n",
    ")\n",
    "workflow.add_edge(\"handle_positive_feedback\", \"add_tool_to_database\")\n",
    "workflow.add_edge(\"handle_negative_feedback\", \"web_search\")\n",
    "\n",
    "# After adding to the database, verify that new stub\n",
    "workflow.add_edge(\"add_tool_to_database\", \"verify_tool_entry\")\n",
    "\n",
    "# Once verification is complete, we END the pipeline\n",
    "workflow.add_edge(\"verify_tool_entry\", END)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Compile\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0c9fcd-ac6d-4fa2-ab5c-c64cf5fc2b25",
   "metadata": {},
   "source": [
    "### Visualize graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a97f26-0be7-4262-806c-cc7355abec1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a584ea8-f97a-4504-a974-25ecbaefb2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f57f7e68-d4c4-47f4-8df7-39f019d38de6",
   "metadata": {},
   "source": [
    "## Run the graph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de45494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_graph_stream(graph, inputs, config=None):\n",
    "    \"\"\"\n",
    "    Consume graph.stream(...) and print each step in a human-readable way.\n",
    "    Knows how to format:\n",
    "      • document_search\n",
    "      • generate\n",
    "      • transform_query\n",
    "      • web_search\n",
    "      • finalize_response\n",
    "      • human_feedback_satisfaction\n",
    "      • handle_positive_feedback\n",
    "      • handle_negative_feedback\n",
    "      • add_tool_to_database\n",
    "      • verify_tool_entry\n",
    "    Any other nodes will be dumped as a raw dict.\n",
    "    \"\"\"\n",
    "    for step in graph.stream(inputs, config or {}):\n",
    "        # step is like {\"document_search\": {...}} or {\"human_feedback_satisfaction\": {...}}, etc.\n",
    "        for node_name, result in step.items():\n",
    "            # 1) document_search\n",
    "            if node_name == \"document_search\":\n",
    "                docs = result.get(\"documents\", [])\n",
    "                q = result.get(\"question\", \"\")\n",
    "                print(f\"[document_search] Retrieved {len(docs)} document(s) for question: {q!r}\")\n",
    "\n",
    "            # 2) generate\n",
    "            elif node_name == \"generate\":\n",
    "                answer = result.get(\"candidate_answer\", \"\").strip()\n",
    "                retries = result.get(\"retries\", 0)\n",
    "                print(f\"[generate] (retry #{retries})\\n{answer}\\n\")\n",
    "\n",
    "            # 3) transform_query\n",
    "            elif node_name == \"transform_query\":\n",
    "                new_q = result.get(\"question\", \"\")\n",
    "                print(f\"[transform_query] Rewrote question to: {new_q!r}\")\n",
    "\n",
    "            # 4) web_search\n",
    "            elif node_name == \"web_search\":\n",
    "                docs = result.get(\"documents\", [])\n",
    "                searched = result.get(\"searched\", False)\n",
    "                if searched and docs:\n",
    "                    src = docs[-1].metadata.get(\"source\", \"<unknown>\")\n",
    "                    print(f\"[web_search] Appended web‐result from {src!r} (now {len(docs)} total docs).\")\n",
    "                else:\n",
    "                    print(f\"[web_search] Ran web search but no new docs found.\")\n",
    "\n",
    "            # 5) finalize_response\n",
    "            elif node_name == \"finalize_response\":\n",
    "                msgs = result.get(\"messages\", [])\n",
    "                for msg in msgs:\n",
    "                    print(f\"[finalize_response] AI: {msg.content.strip()}\\n\")\n",
    "\n",
    "            # 6) human_feedback_satisfaction\n",
    "            elif node_name == \"human_feedback_satisfaction\":\n",
    "                feedback = result.get(\"user_feedback\", \"<no feedback>\")\n",
    "                print(f\"[human_feedback_satisfaction] User answered: {feedback!r}\")\n",
    "\n",
    "            # 7) handle_positive_feedback\n",
    "            elif node_name == \"handle_positive_feedback\":\n",
    "                code = result.get(\"sample_code\", \"\").strip()\n",
    "                print(\"[handle_positive_feedback] Generated code stub:\\n\")\n",
    "                print(code + \"\\n\")\n",
    "\n",
    "            # 8) handle_negative_feedback\n",
    "            elif node_name == \"handle_negative_feedback\":\n",
    "                new_q = result.get(\"question\", \"\")\n",
    "                print(f\"[handle_negative_feedback] Updated question for next search:\\n  {new_q!r}\")\n",
    "\n",
    "            # 9) add_tool_to_database\n",
    "            elif node_name == \"add_tool_to_database\":\n",
    "                # We check if \"searched\" was True in the result\n",
    "                if result.get(\"searched\", False):\n",
    "                    print(\"[add_tool_to_database] Attempted to add a new tool stub (searched=True).\")\n",
    "                else:\n",
    "                    print(\"[add_tool_to_database] No new tool was added (searched=False).\")\n",
    "\n",
    "            # 10) verify_tool_entry\n",
    "            elif node_name == \"verify_tool_entry\":\n",
    "                print(\"[verify_tool_entry] Finished verifying tools. Check JSON files for missing/fixed/improved stubs.\")\n",
    "\n",
    "            # 11) Any other node → raw dump\n",
    "            else:\n",
    "                print(f\"[{node_name!r}] {result}\")\n",
    "\n",
    "        print(\"─\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc5717-b25f-4b6b-8542-514700deb11f",
   "metadata": {},
   "source": [
    "### Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe4f2af-83f3-4ea1-96e9-3944764def12",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True\n",
    "inputs = {\"messages\": [(\"human\", \"I want a tool that can act as a calculator\")]}\n",
    "pretty_print_graph_stream(graph, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e11da3-5ec0-4cac-9b0c-9f8b2f642983",
   "metadata": {},
   "source": [
    "#### Query with a fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eab445-6fbf-4a56-b010-2ba4e4f06371",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE = True\n",
    "inputs = {\"messages\": [(\"human\", \"I want a tool that can act as a search engine for finding places on google maps\")]}\n",
    "pretty_print_graph_stream(graph, inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
